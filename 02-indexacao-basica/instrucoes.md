# ğŸ“¥ Etapa 02 â€“ IndexaÃ§Ã£o de 10.000 Hosts de Infraestrutura

Nesta etapa vocÃª irÃ¡ criar e popular um Ã­ndice Elasticsearch chamado **infra-hosts** com **10.000 documentos simulados** de servidores (hosts).  
Os dados possuem timestamps distribuÃ­dos ao longo de **agosto/2025**.

---

## ğŸš€ Passos

### 1A) IngestÃ£o rÃ¡pida (Bulk via cURL)
Use o script otimizado de bulk (converte NDJSON â†’ formato Bulk em stream):

```bash
# dar permissÃ£o
chmod +x ingestar-bulk.sh

# executar com defaults:
# ES_URL=http://localhost:9200, INDEX=infra-hosts, FILE=dados-10000-ago-2025.ndjson
./ingestar-bulk.sh

# ou customizando:
ES_URL=http://localhost:9200 INDEX=infra-hosts FILE=dados-10000-ago-2025.ndjson ./ingestar-bulk.sh
```

> O script recria o Ã­ndice (settings + mappings), desliga o `refresh` durante o bulk e reativa ao final.

---

### 1B) IngestÃ£o alternativa (Logstash)
Se preferir transformar/validar na entrada, use o Logstash com **arquivo dedicado**:

- Arquivo de dados: `02-indexacao-basica/dados-10000-ago-2025-logstash.ndjson`  
- Pipeline: `02-indexacao-basica/logstash.conf`  
- Compose override: `docker-compose.override.yml` (jÃ¡ mapeando os caminhos acima)

Suba o Logstash junto do stack:

```bash
docker compose up -d logstash
docker logs -f logstash   # acompanhe a ingestÃ£o (pontos no log)
```

No pipeline:
- Cada documento recebe um **_id determinÃ­stico** (`host@timestamp`) â†’ a ingestÃ£o Ã© idempotente.  
- Ã‰ adicionado o campo `"ingest": "logstash"` â†’ permitindo diferenciar dados do Logstash dos dados do Bulk.  

> Por padrÃ£o, o pipeline indexa no Ã­ndice `infra-hosts`.  
> Para rodar sem Logstash, suba apenas `elasticsearch` e `kibana`.

---

## 2) Verificar a ingestÃ£o

### Usando cURL:
```bash
# Contagem total (esperado: 10000 se usou sÃ³ um mÃ©todo; ~20000 se usou Bulk + Logstash)
curl -s "http://localhost:9200/infra-hosts/_count?pretty"

# Amostra (5 docs), ordenados por tempo desc
curl -s -H 'Content-Type: application/json' -X POST "http://localhost:9200/infra-hosts/_search?pretty" -d '{
  "size": 5,
  "sort": [{"@timestamp":"desc"}],
  "query": { "match_all": {} }
}'

# Apenas agosto/2025 (filtro de data)
curl -s -H 'Content-Type: application/json' -X POST "http://localhost:9200/infra-hosts/_search?pretty" -d '{
  "size": 0,
  "query": {
    "range": { "@timestamp": { "gte": "2025-08-01", "lte": "2025-08-31T23:59:59" } }
  }
}'

# Apenas documentos do Logstash
curl -s -H 'Content-Type: application/json' -X POST "http://localhost:9200/infra-hosts/_search?pretty" -d '{
  "size": 0,
  "query": { "term": { "ingest": "logstash" } }
}'
```

### Usando Kibana Dev Tools:
```json
GET infra-hosts/_count

GET infra-hosts/_search
{
  "size": 5,
  "sort": [{ "@timestamp": "desc" }],
  "query": { "match_all": {} }
}

GET infra-hosts/_search
{
  "size": 0,
  "query": {
    "range": { "@timestamp": { "gte": "2025-08-01", "lte": "2025-08-31T23:59:59" } }
  }
}

# Apenas documentos do Logstash
GET infra-hosts/_search
{
  "size": 0,
  "query": { "term": { "ingest": "logstash" } }
}
```

---

## ğŸ“Š Campos disponÃ­veis
- `host`: identificador do servidor (ex: `srv-web-00001`)
- `servico`: serviÃ§o (ex: `webserver`, `api`, `database`, `auth-service`, `cache`, `queue`, `search`, `payments`, `analytics`)
- `status`: estado do serviÃ§o (`online`, `warning`, `offline`)
- `cpu`: uso de CPU (%)
- `memoria`: uso de memÃ³ria (%)
- `@timestamp`: data/hora da coleta (agosto/2025)
- `ingest`: origem da ingestÃ£o (`bulk` ou `logstash`)

---

## âœ… Checklist de validaÃ§Ã£o
1. O Ã­ndice `infra-hosts` foi criado corretamente (`GET _cat/indices?v`).  
2. Existem **10.000 documentos** no Ã­ndice (se usou apenas um mÃ©todo) ou ~20.000 (se rodou Bulk + Logstash).  
3. O filtro de data retorna apenas registros de **agosto/2025**.  
4. O campo `ingest` permite diferenciar a origem dos documentos.  
5. (Se usar Logstash) os logs mostram progresso e finalizaÃ§Ã£o sem erros; a contagem bate com o esperado.

---

## ğŸ› ï¸ Boas prÃ¡ticas e dicas extras

- **ValidaÃ§Ã£o do dataset**  
  Antes de ingerir, confira se o arquivo tem de fato 10.000 linhas:  
  ```bash
  wc -l dados-10000-ago-2025.ndjson
  ```

- **Evite duplicaÃ§Ã£o de documentos**  
  Se nÃ£o definir `_id`, o Elasticsearch gera automaticamente um UUID.  
  â†’ No Bulk isso pode duplicar docs caso rode 2x o mesmo arquivo.  
  â†’ No Logstash o `_id` foi configurado como `host@timestamp` â†’ garante idempotÃªncia.

- **Controle de performance**  
  Durante ingestÃ£o em massa, Ã© comum desligar o `refresh_interval` e usar `number_of_replicas=0`.  
  Isso jÃ¡ estÃ¡ implementado nos scripts.  
  Depois da ingestÃ£o, o `refresh` volta ao normal para as buscas funcionarem.

- **Debug de erros comuns**  
  - `400 Bad Request` â†’ formato NDJSON errado (verifique que cada doc ocupa uma linha).  
  - `mapper_parsing_exception` â†’ campo com tipo incorreto (ex.: string em campo integer).  
  - Dica: rode o bulk com `--verbose` ou verifique o log do Logstash para ver quais docs falharam.

- **Primeira visualizaÃ§Ã£o no Kibana**  
  ApÃ³s a ingestÃ£o, vÃ¡ em **Kibana â†’ Discover** e selecione o data view `infra-hosts`.  
  Teste filtros rÃ¡pidos:  
  - `status:warning`  
  - `cpu > 90`  
  - `memoria > 85`

---

Pronto! Agora vocÃª tem a ingestÃ£o por **Bulk** (rÃ¡pida) e por **Logstash** (flexÃ­vel e idempotente), ambas apontando para datasets distintos â€” perfeito para demonstrar dois fluxos comuns de indexaÃ§Ã£o no dia a dia, com boas prÃ¡ticas aplicadas.
