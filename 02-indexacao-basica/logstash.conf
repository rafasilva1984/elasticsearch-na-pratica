input {
  file {
    path => "${DATA_FILE:/data/dados-10000-ago-2025-logstash.ndjson}"
    start_position => "beginning"
    sincedb_path   => "/dev/null"     # sempre reler do início
    codec => json
  }
}

filter {
  # 1) Timestamp válido (o seu dataset já vem ISO8601)
  date { match => ["@timestamp", "ISO8601"] }

  # 2) Normalizações
  mutate {
    lowercase => ["status"]
    add_field => { "ingest" => "logstash" }   # marca de origem
  }

  # 3) _id determinístico = host@timestamp
  #    @timestamp aqui é LogStash::Timestamp -> convertemos pra ISO8601
  ruby {
    code => '
      host = event.get("host")
      ts   = event.get("@timestamp")
      ts_s = ts.respond_to?(:time) ? ts.time.iso8601 : ts.to_s
      event.set("[@metadata][_doc_id]", "#{host}@#{ts_s}")
    '
  }
}

output {
  elasticsearch {
    hosts        => ["${ES_HOST:http://elasticsearch:9200}"]
    index        => "${INDEX:infra-hosts}"
    action       => "index"
    document_id  => "%{[@metadata][_doc_id]}"   # <- usa o ID determinístico
  }
  stdout { codec => dots }
}
